# Chess Tournament - Game Playing AI

Há»‡ thá»‘ng giáº£i Ä‘áº¥u cá» vua vá»›i cÃ¡c AI agents sá»­ dá»¥ng thuáº­t toÃ¡n Minimax vÃ  Machine Learning.

> **BÃ i táº­p lá»›n mÃ´n TrÃ­ tuá»‡ NhÃ¢n táº¡o - HCMUT**

## ğŸ“‹ Má»¥c tiÃªu dá»± Ã¡n

- Hiá»‡n thá»±c game playing agent cho trÃ² chÆ¡i cá» vua (Ä‘á»‘i khÃ¡ng)
- So sÃ¡nh hiá»‡u quáº£ giá»¯a thuáº­t toÃ¡n Minimax vÃ  Machine Learning
- ÄÃ¡p á»©ng yÃªu cáº§u:
  - âœ… Agent chÆ¡i Ä‘Ãºng luáº­t cá» vua
  - âœ… Minimax tháº¯ng Random â‰¥ 90%
  - âœ… Machine Learning tháº¯ng Random â‰¥ 60%

## ğŸ® TÃ­nh nÄƒng

### AI Agents

| Agent | MÃ´ táº£ | Win Rate vs Random |
|-------|-------|-------------------|
| **Random** | Chá»n nÆ°á»›c Ä‘i ngáº«u nhiÃªn | - |
| **Minimax** | Alpha-beta pruning, depth 3 | ~100% |
| **ML (Random Forest)** | Machine Learning vá»›i 300 trees | ~70% |

### Giao diá»‡n Ä‘á»“ há»a

- **Tournament Management**: Táº¡o vÃ  quáº£n lÃ½ giáº£i Ä‘áº¥u
- **Live Statistics**: Theo dÃµi káº¿t quáº£ realtime
- **Replay System**: Xem láº¡i cÃ¡c vÃ¡n Ä‘áº¥u vá»›i playback controls

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u

- Python 3.8+
- Windows/Linux/macOS

### CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### Dependencies

```
chess==1.11.2
numpy==2.3.4
pygame==2.6.1
scikit-learn>=1.3.0
```

## ğŸ“– HÆ°á»›ng dáº«n sá»­ dá»¥ng

### Cháº¡y á»©ng dá»¥ng chÃ­nh

```bash
python main.py
```

### Train láº¡i ML Model (tuá»³ chá»n)

```bash
python ml_training.py
```

### Test tá»‰ lá»‡ tháº¯ng

```bash
# Test vá»›i 100 games (máº·c Ä‘á»‹nh)
python test_agents.py

# Test vá»›i sá»‘ games tuá»³ chá»n
python test_agents.py 50
```

## ğŸ§  Chi tiáº¿t cÃ¡c AI Agents

### 1. Random Agent

Agent cÆ¡ báº£n nháº¥t, chá»n ngáº«u nhiÃªn tá»« cÃ¡c nÆ°á»›c Ä‘i há»£p lá»‡.

```python
def get_move(self, board):
    return random.choice(list(board.legal_moves))
```

### 2. Minimax Agent (75% Ä‘iá»ƒm BTL)

Sá»­ dá»¥ng thuáº­t toÃ¡n **Minimax vá»›i Alpha-Beta Pruning**:

- **Äá»™ sÃ¢u**: 3 ply (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh)
- **Evaluation function**: ÄÃ¡nh giÃ¡ tá»« gÃ³c nhÃ¬n White
- **Alpha-Beta Pruning**: Cáº¯t tá»‰a Ä‘á»ƒ tÄƒng tá»‘c

**Báº£ng giÃ¡ trá»‹ quÃ¢n cá»:**

| QuÃ¢n | GiÃ¡ trá»‹ |
|------|---------|
| Pawn | 100 |
| Knight | 320 |
| Bishop | 330 |
| Rook | 500 |
| Queen | 900 |
| King | 20000 |

**Pseudocode:**

```
function minimax(board, depth, alpha, beta, maximizing):
    if depth == 0 or game_over:
        return evaluate(board)
    
    if maximizing:
        maxEval = -âˆ
        for each move:
            eval = minimax(board, depth-1, alpha, beta, false)
            maxEval = max(maxEval, eval)
            alpha = max(alpha, eval)
            if beta <= alpha:
                break  # Cáº¯t tá»‰a
        return maxEval
    else:
        minEval = +âˆ
        for each move:
            eval = minimax(board, depth-1, alpha, beta, true)
            minEval = min(minEval, eval)
            beta = min(beta, eval)
            if beta <= alpha:
                break  # Cáº¯t tá»‰a
        return minEval
```

### 3. ML Agent - Random Forest (25% Ä‘iá»ƒm BTL)

Sá»­ dá»¥ng **Random Forest Regressor** Ä‘Æ°á»£c train tá»« self-play data.

#### Feature Engineering (21 features)

| # | Feature | MÃ´ táº£ |
|---|---------|-------|
| 1-6 | Material Difference | ChÃªnh lá»‡ch sá»‘ quÃ¢n (Pawn, Knight, Bishop, Rook, Queen, King) |
| 7-8 | Total Material | Tá»•ng giÃ¡ trá»‹ quÃ¢n cá» má»—i bÃªn |
| 9 | Mobility | Sá»‘ nÆ°á»›c Ä‘i há»£p lá»‡ hiá»‡n táº¡i |
| 10-11 | Center Control | Kiá»ƒm soÃ¡t trung tÃ¢m (e4, e5, d4, d5) vÃ  vÃ¹ng má»Ÿ rá»™ng |
| 12-15 | Castling Rights | Quyá»n nháº­p thÃ nh (4 features) |
| 16-17 | King Safety | Vá»‹ trÃ­ an toÃ n cá»§a vua |
| 18-19 | Pawn Structure | Cáº¥u trÃºc tá»‘t |
| 20 | Is Check | Äang bá»‹ chiáº¿u? |
| 21 | Turn Indicator | LÆ°á»£t Ä‘i (White = 1, Black = -1) |

#### Training Process

```
1. Generate Self-Play Data:
   - 3000 random games
   - 2000 strategic games (with simple heuristic)
   - Total: ~650,000 positions

2. Train Random Forest:
   - n_estimators: 300
   - max_depth: 20
   - RÂ² score: ~0.37

3. Inference:
   - Batch prediction cho táº¥t cáº£ nÆ°á»›c Ä‘i
   - Chá»n nÆ°á»›c cÃ³ score cao nháº¥t (White) hoáº·c tháº¥p nháº¥t (Black)
```

#### Tá»‘i Æ°u tá»‘c Ä‘á»™

- **Batch Prediction**: Gom táº¥t cáº£ features vÃ  predict 1 láº§n
- **Feature tá»‘i Æ°u**: Loáº¡i bá» tÃ­nh toÃ¡n phá»©c táº¡p
- **Káº¿t quáº£**: ~100x nhanh hÆ¡n so vá»›i predict tá»«ng nÆ°á»›c

## ğŸ“Š Káº¿t quáº£ Ä‘Ã¡nh giÃ¡

### Test vá»›i 100 games

| Agent | Wins | Losses | Draws | Win Rate | YÃªu cáº§u | Status |
|-------|------|--------|-------|----------|---------|--------|
| **Minimax** vs Random | 100 | 0 | 0 | **100%** | â‰¥90% | âœ… PASS |
| **ML** vs Random | 70 | 2 | 28 | **70%** | â‰¥60% | âœ… PASS |

### PhÃ¢n tÃ­ch

- **Minimax**: Hiá»‡u quáº£ ráº¥t cao nhá» tÃ¬m kiáº¿m cÃ³ chiá»u sÃ¢u
- **ML Agent**: Há»c Ä‘Æ°á»£c patterns cÆ¡ báº£n tá»« self-play data, Ä‘á»§ Ä‘á»ƒ tháº¯ng Random má»™t cÃ¡ch á»•n Ä‘á»‹nh

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
chess-tournament/
â”œâ”€â”€ agents.py           # Äá»‹nh nghÄ©a cÃ¡c AI agents
â”œâ”€â”€ main.py             # á»¨ng dá»¥ng chÃ­nh vá»›i GUI
â”œâ”€â”€ tournament.py       # Quáº£n lÃ½ giáº£i Ä‘áº¥u
â”œâ”€â”€ ui_components.py    # UI components
â”œâ”€â”€ ml_training.py      # Script train ML model
â”œâ”€â”€ test_agents.py      # Script test tá»‰ lá»‡ tháº¯ng
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ README.md           # File nÃ y
â”œâ”€â”€ ml_models/
â”‚   â””â”€â”€ chess_rf_model.pkl  # Trained Random Forest model
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ img/            # HÃ¬nh áº£nh quÃ¢n cá» vÃ  UI
â””â”€â”€ tournaments/        # LÆ°u káº¿t quáº£ giáº£i Ä‘áº¥u
    â””â”€â”€ <tournament_name>/
        â”œâ”€â”€ result.txt
        â”œâ”€â”€ game1_Minimax.txt
        â””â”€â”€ ...
```

## ğŸ¯ Äá»™ phá»©c táº¡p cá»§a trÃ² chÆ¡i

Cá» vua Ä‘Ã¡p á»©ng yÃªu cáº§u BTL:

- **Há»‡ sá»‘ nhÃ¡nh trung bÃ¬nh**: ~35 nÆ°á»›c Ä‘i/lÆ°á»£t
- **Äá»™ sÃ¢u cÃ¢y game**: 40-50 nÆ°á»›c má»—i bÃªn (~80-100 ply) > 30 âœ…
- **KhÃ´ng gian tráº¡ng thÃ¡i**: ~10^44 vá»‹ trÃ­ cÃ³ thá»ƒ

## ğŸ”§ Cáº¥u hÃ¬nh nÃ¢ng cao

### Thay Ä‘á»•i Ä‘á»™ sÃ¢u Minimax

Trong `agents.py`:

```python
def create_agent(agent_type: str, name: str = None) -> Agent:
    elif agent_type.lower() == "minimax":
        return MinimaxAgent(name or "Minimax", depth=4)  # Thay Ä‘á»•i depth
```

### Train láº¡i ML Model vá»›i tham sá»‘ khÃ¡c

Trong `ml_training.py`:

```python
train_and_save(
    num_random_games=5000,      # TÄƒng sá»‘ games
    num_strategic_games=3000,   
    n_estimators=500,           # Nhiá»u trees hÆ¡n
    max_depth=25                # SÃ¢u hÆ¡n
)
```

## ğŸ“ Ghi chÃº

- Model ML Ä‘Ã£ Ä‘Æ°á»£c train sáºµn trong `ml_models/chess_rf_model.pkl`
- Náº¿u muá»‘n train láº¡i, cháº¡y `python ml_training.py` (máº¥t ~2-3 phÃºt)
- Káº¿t quáº£ giáº£i Ä‘áº¥u Ä‘Æ°á»£c lÆ°u tá»± Ä‘á»™ng trong thÆ° má»¥c `tournaments/`

## ğŸ‘¥ ThÃ nh viÃªn nhÃ³m

- [ThÃªm thÃ´ng tin thÃ nh viÃªn á»Ÿ Ä‘Ã¢y]

## ğŸ“„ License

Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch há»c táº­p táº¡i HCMUT.
